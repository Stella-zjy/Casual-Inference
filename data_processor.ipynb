{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import graphviz as gr\n",
    "from linearmodels.iv import IV2SLS\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 5)\n",
    "style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       age  workclass  ...  native-country income_>50K\n0       67    Private  ...   United-States           1\n1       17    Private  ...   United-States           0\n2       31    Private  ...   United-States           1\n3       58  State-gov  ...   United-States           0\n4       25  State-gov  ...   United-States           0\n...    ...        ...  ...             ...         ...\n43952   52    Private  ...   United-States           1\n43953   19    Private  ...   United-States           0\n43954   30    Private  ...   United-States           0\n43955   46    Private  ...   United-States           0\n43956   30    Private  ...   United-States           0\n\n[40727 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>...</th>\n      <th>native-country</th>\n      <th>income_&gt;50K</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>67</td>\n      <td>Private</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>Private</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31</td>\n      <td>Private</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>58</td>\n      <td>State-gov</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25</td>\n      <td>State-gov</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43952</th>\n      <td>52</td>\n      <td>Private</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43953</th>\n      <td>19</td>\n      <td>Private</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43954</th>\n      <td>30</td>\n      <td>Private</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43955</th>\n      <td>46</td>\n      <td>Private</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43956</th>\n      <td>30</td>\n      <td>Private</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>40727 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../Casual-Inference/data/income_data/train.csv\")\n",
    "data = data.dropna()\n",
    "data.describe()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([16,  8, 13,  4, 10,  9,  5,  6,  7, 14,  1,  3, 15, 11, 12,  2])"
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna(axis = 0)\n",
    "data = data.loc[:, [\"race\", \"educational-num\", \"age\", \"income_>50K\", \"occupation\", \"relationship\", \"marital-status\", \"native-country\", \"gender\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"workclass\"]]\n",
    "data.rename(columns = {'educational-num':'educational_num', \"income_>50K\": \"income_bigger_than_50K\", 'marital-status':'marital_status'}, inplace = True)\n",
    "data[\"race\"] = data[\"race\"].replace(to_replace =\"Amer-Indian-Eskimo\",\n",
    "                 value =\"Indian\")\n",
    "data[\"race\"] = data[\"race\"].replace(to_replace =\"Asian-Pac-Islander\",\n",
    "                 value =\"Asian\")\n",
    "occupationDict = {\n",
    "    \"Exec-managerial\" : 0,\n",
    "    \"Other-service\" : 1,\n",
    "    \"Transport-moving\" : 2,\n",
    "    \"Adm-clerical\" : 3,\n",
    "    \"Machine-op-inspct\" : 4,\n",
    "    \"Sales\" : 5,\n",
    "    \"Handlers-cleaners\" : 6,\n",
    "    \"Farming-fishing\" : 7,\n",
    "    \"Protective-serv\" : 8,\n",
    "    \"Prof-specialty\" : 9,\n",
    "    \"Craft-repair\" : 10,\n",
    "    \"Tech-support\" : 11,\n",
    "    \"Priv-house-serv\" : 12,\n",
    "    \"Armed-Forces\" : 13\n",
    "}\n",
    "raceDict = {\n",
    "    \"White\" : 0,\n",
    "    \"Black\" : 1,\n",
    "    \"Asian\" : 2,\n",
    "    \"Indian\" : 3,\n",
    "    \"Other\" : 4\n",
    "}\n",
    "genderDict = {\n",
    "    \"Male\" : 0,\n",
    "    \"Female\" : 1\n",
    "}\n",
    "maritalDict = {\n",
    "    \"Divorced\":0,\n",
    "    \"Never-married\":1,\n",
    "    \"Married-civ-spouse\":2,\n",
    "    \"Widowed\":3,\n",
    "    \"Separated\":4,\n",
    "    \"Married-spouse-absent\":5,\n",
    "    \"Married-AF-spouse\":6\n",
    "}\n",
    "countryDict = {\n",
    "    'United-States': 0,\n",
    "    'Japan': 1,\n",
    "    'South': 2,\n",
    "    'Portugal': 3,\n",
    "    'Italy': 4,\n",
    "    'Mexico': 5,\n",
    "    'Ecuador': 6,\n",
    "    'England':7 ,\n",
    "    'Philippines': 8,\n",
    "    'China': 9,\n",
    "    'Germany': 10,\n",
    "    'Dominican-Republic': 11,\n",
    "    'Jamaica': 12,\n",
    "    'Vietnam': 13,\n",
    "    'Thailand': 14,\n",
    "    'Puerto-Rico': 15,\n",
    "    'Cuba': 16,\n",
    "    'India': 17,\n",
    "    'Cambodia': 18,\n",
    "    'Yugoslavia': 19,\n",
    "    'Iran': 20,\n",
    "    'El-Salvador': 21,\n",
    "    'Poland': 22,\n",
    "    'Greece': 23,\n",
    "    'Ireland': 24,\n",
    "    'Canada': 25,\n",
    "    'Guatemala': 26,\n",
    "    'Scotland': 27,\n",
    "    'Columbia': 28,\n",
    "    'Outlying-US(Guam-USVI-etc)': 29,\n",
    "    'Haiti': 30,\n",
    "    'Peru': 31,\n",
    "    'Nicaragua': 32,\n",
    "    'Trinadad&Tobago': 33,\n",
    "    'Laos': 34,\n",
    "    'Taiwan': 35,\n",
    "    'France': 36,\n",
    "    'Hungary': 37,\n",
    "    'Honduras': 38,\n",
    "    'Hong': 39,\n",
    "    'Holand-Netherlands': 40\n",
    "}\n",
    "workclassDict = {\n",
    "    'Private': 0,\n",
    "    'State-gov': 1,\n",
    "    'Self-emp-not-inc': 2,\n",
    "    'Federal-gov': 3,\n",
    "    'Local-gov': 4,\n",
    "    'Self-emp-inc': 5,\n",
    "    'Without-pay': 6\n",
    "}\n",
    "def map_age(age):\n",
    "    if age < 20 or age > 90: return -1\n",
    "    if 20 <= age < 25: return 1\n",
    "    if 25 <= age < 30: return 2\n",
    "    if 30 <= age < 35: return 3\n",
    "    if 35 <= age < 40: return 4\n",
    "    if 40 <= age < 45: return 5\n",
    "    if 45 <= age < 50: return 6\n",
    "    if 50 <= age < 60: return 7\n",
    "    if 60 <= age < 75: return 8\n",
    "    if 75 <= age < 90: return 9\n",
    "\n",
    "data[\"occupation\"] = data[\"occupation\"].map(occupationDict)\n",
    "data[\"race\"] = data[\"race\"].map(raceDict)\n",
    "data[\"gender\"] = data[\"gender\"].map(genderDict)\n",
    "data[\"age_interval\"] = data[\"age\"].map(map_age)\n",
    "data[\"marital_status\"] = data[\"marital_status\"].map(maritalDict)\n",
    "data[\"native-country\"] = data[\"native-country\"].map(countryDict)\n",
    "data[\"workclass\"] = data[\"workclass\"].map(workclassDict)\n",
    "data[\"educational_num\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       educational_num  age  ...  hours-per-week  workclass\n0                   16   67  ...              60          0\n1                    8   17  ...              15          0\n2                   13   31  ...              40          0\n3                    4   58  ...              40          1\n4                   10   25  ...              40          1\n...                ...  ...  ...             ...        ...\n43952               13   52  ...              50          0\n43953                9   19  ...              40          0\n43954               10   30  ...              58          0\n43955               13   46  ...              35          0\n43956                9   30  ...              40          0\n\n[40727 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>educational_num</th>\n      <th>age</th>\n      <th>...</th>\n      <th>hours-per-week</th>\n      <th>workclass</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>67</td>\n      <td>...</td>\n      <td>60</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>17</td>\n      <td>...</td>\n      <td>15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13</td>\n      <td>31</td>\n      <td>...</td>\n      <td>40</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>58</td>\n      <td>...</td>\n      <td>40</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10</td>\n      <td>25</td>\n      <td>...</td>\n      <td>40</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43952</th>\n      <td>13</td>\n      <td>52</td>\n      <td>...</td>\n      <td>50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43953</th>\n      <td>9</td>\n      <td>19</td>\n      <td>...</td>\n      <td>40</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43954</th>\n      <td>10</td>\n      <td>30</td>\n      <td>...</td>\n      <td>58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43955</th>\n      <td>13</td>\n      <td>46</td>\n      <td>...</td>\n      <td>35</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43956</th>\n      <td>9</td>\n      <td>30</td>\n      <td>...</td>\n      <td>40</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>40727 rows Ã— 10 columns</p>\n</div>"
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[['educational_num', 'age', 'race', 'gender', 'marital_status', 'native-country', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass']]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        0\n1        1\n2        0\n3        2\n4        1\n        ..\n43952    0\n43953    1\n43954    5\n43955    5\n43956    6\nName: occupation, Length: 40727, dtype: int64"
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['occupation']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "y_train_encoded=encoder.fit_transform(y_train)\n",
    "y_val_encoded=encoder.fit_transform(y_val)\n",
    "y_test_encoded=encoder.fit_transform(y_test)\n",
    "\n",
    "y_train_cat=to_categorical(y_train_encoded)\n",
    "y_val_cat=to_categorical(y_val_encoded)\n",
    "y_test_cat=to_categorical(y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "974/974 [==============================] - 2s 2ms/step - loss: 3.9293 - accuracy: 0.2076 - val_loss: 2.1706 - val_accuracy: 0.2490\n",
      "Epoch 2/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 2.1584 - accuracy: 0.2550 - val_loss: 2.1825 - val_accuracy: 0.2397\n",
      "Epoch 3/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 2.1006 - accuracy: 0.2672 - val_loss: 2.0619 - val_accuracy: 0.2704\n",
      "Epoch 4/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 2.0593 - accuracy: 0.2847 - val_loss: 2.0378 - val_accuracy: 0.2884\n",
      "Epoch 5/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 2.0310 - accuracy: 0.2945 - val_loss: 2.0261 - val_accuracy: 0.2851\n",
      "Epoch 6/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 2.0137 - accuracy: 0.2989 - val_loss: 2.0127 - val_accuracy: 0.2975\n",
      "Epoch 7/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 2.0042 - accuracy: 0.3038 - val_loss: 2.0286 - val_accuracy: 0.2944\n",
      "Epoch 8/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 2.0236 - accuracy: 0.3038 - val_loss: 1.9985 - val_accuracy: 0.3008\n",
      "Epoch 9/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9917 - accuracy: 0.3055 - val_loss: 1.9920 - val_accuracy: 0.3030\n",
      "Epoch 10/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9850 - accuracy: 0.3087 - val_loss: 1.9914 - val_accuracy: 0.3081\n",
      "Epoch 11/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 2.0153 - accuracy: 0.3087 - val_loss: 2.0077 - val_accuracy: 0.2946\n",
      "Epoch 12/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9716 - accuracy: 0.3128 - val_loss: 1.9729 - val_accuracy: 0.3106\n",
      "Epoch 13/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9633 - accuracy: 0.3111 - val_loss: 1.9759 - val_accuracy: 0.3071\n",
      "Epoch 14/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9581 - accuracy: 0.3131 - val_loss: 1.9664 - val_accuracy: 0.3151\n",
      "Epoch 15/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9505 - accuracy: 0.3182 - val_loss: 1.9732 - val_accuracy: 0.3010\n",
      "Epoch 16/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9450 - accuracy: 0.3174 - val_loss: 1.9561 - val_accuracy: 0.3119\n",
      "Epoch 17/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9412 - accuracy: 0.3196 - val_loss: 1.9543 - val_accuracy: 0.3190\n",
      "Epoch 18/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9373 - accuracy: 0.3205 - val_loss: 1.9554 - val_accuracy: 0.3144\n",
      "Epoch 19/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9334 - accuracy: 0.3197 - val_loss: 1.9561 - val_accuracy: 0.3170\n",
      "Epoch 20/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9305 - accuracy: 0.3236 - val_loss: 1.9503 - val_accuracy: 0.3122\n",
      "Epoch 21/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9280 - accuracy: 0.3222 - val_loss: 1.9545 - val_accuracy: 0.3155\n",
      "Epoch 22/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9258 - accuracy: 0.3237 - val_loss: 1.9549 - val_accuracy: 0.3122\n",
      "Epoch 23/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.9230 - accuracy: 0.3255 - val_loss: 1.9510 - val_accuracy: 0.3137\n",
      "Epoch 24/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9203 - accuracy: 0.3265 - val_loss: 1.9512 - val_accuracy: 0.3141\n",
      "Epoch 25/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9178 - accuracy: 0.3265 - val_loss: 1.9521 - val_accuracy: 0.3177\n",
      "Epoch 26/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9162 - accuracy: 0.3254 - val_loss: 1.9459 - val_accuracy: 0.3226\n",
      "Epoch 27/200\n",
      "974/974 [==============================] - 2s 2ms/step - loss: 1.9148 - accuracy: 0.3272 - val_loss: 1.9478 - val_accuracy: 0.3170\n",
      "Epoch 28/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9167 - accuracy: 0.3282 - val_loss: 1.9500 - val_accuracy: 0.3195\n",
      "Epoch 29/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9112 - accuracy: 0.3286 - val_loss: 1.9482 - val_accuracy: 0.3182\n",
      "Epoch 30/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9088 - accuracy: 0.3277 - val_loss: 1.9391 - val_accuracy: 0.3226\n",
      "Epoch 31/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9077 - accuracy: 0.3298 - val_loss: 1.9452 - val_accuracy: 0.3151\n",
      "Epoch 32/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9072 - accuracy: 0.3282 - val_loss: 1.9457 - val_accuracy: 0.3137\n",
      "Epoch 33/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9052 - accuracy: 0.3324 - val_loss: 1.9428 - val_accuracy: 0.3201\n",
      "Epoch 34/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9040 - accuracy: 0.3314 - val_loss: 1.9453 - val_accuracy: 0.3244\n",
      "Epoch 35/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9031 - accuracy: 0.3298 - val_loss: 1.9485 - val_accuracy: 0.3228\n",
      "Epoch 36/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9019 - accuracy: 0.3315 - val_loss: 1.9428 - val_accuracy: 0.3226\n",
      "Epoch 37/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.9002 - accuracy: 0.3299 - val_loss: 1.9467 - val_accuracy: 0.3191\n",
      "Epoch 38/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8986 - accuracy: 0.3303 - val_loss: 1.9444 - val_accuracy: 0.3210\n",
      "Epoch 39/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8975 - accuracy: 0.3316 - val_loss: 1.9479 - val_accuracy: 0.3210\n",
      "Epoch 40/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8972 - accuracy: 0.3339 - val_loss: 1.9449 - val_accuracy: 0.3208\n",
      "Epoch 41/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8964 - accuracy: 0.3329 - val_loss: 1.9486 - val_accuracy: 0.3253\n",
      "Epoch 42/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8956 - accuracy: 0.3328 - val_loss: 1.9459 - val_accuracy: 0.3206\n",
      "Epoch 43/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8947 - accuracy: 0.3323 - val_loss: 1.9465 - val_accuracy: 0.3235\n",
      "Epoch 44/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8929 - accuracy: 0.3340 - val_loss: 1.9486 - val_accuracy: 0.3215\n",
      "Epoch 45/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8920 - accuracy: 0.3347 - val_loss: 1.9505 - val_accuracy: 0.3202\n",
      "Epoch 46/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8919 - accuracy: 0.3348 - val_loss: 1.9466 - val_accuracy: 0.3222\n",
      "Epoch 47/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.8902 - accuracy: 0.3364 - val_loss: 1.9506 - val_accuracy: 0.3228\n",
      "Epoch 48/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.8907 - accuracy: 0.3330 - val_loss: 1.9515 - val_accuracy: 0.3210\n",
      "Epoch 49/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8899 - accuracy: 0.3349 - val_loss: 1.9476 - val_accuracy: 0.3210\n",
      "Epoch 50/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8885 - accuracy: 0.3359 - val_loss: 1.9504 - val_accuracy: 0.3217\n",
      "Epoch 51/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8879 - accuracy: 0.3341 - val_loss: 1.9529 - val_accuracy: 0.3217\n",
      "Epoch 52/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.8873 - accuracy: 0.3368 - val_loss: 1.9587 - val_accuracy: 0.3208\n",
      "Epoch 53/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8862 - accuracy: 0.3383 - val_loss: 1.9500 - val_accuracy: 0.3221\n",
      "Epoch 54/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8858 - accuracy: 0.3370 - val_loss: 1.9539 - val_accuracy: 0.3219\n",
      "Epoch 55/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8851 - accuracy: 0.3378 - val_loss: 1.9508 - val_accuracy: 0.3239\n",
      "Epoch 56/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8850 - accuracy: 0.3358 - val_loss: 1.9525 - val_accuracy: 0.3222\n",
      "Epoch 57/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8839 - accuracy: 0.3372 - val_loss: 1.9505 - val_accuracy: 0.3239\n",
      "Epoch 58/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8832 - accuracy: 0.3377 - val_loss: 1.9503 - val_accuracy: 0.3235\n",
      "Epoch 59/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8826 - accuracy: 0.3342 - val_loss: 1.9543 - val_accuracy: 0.3246\n",
      "Epoch 60/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8825 - accuracy: 0.3372 - val_loss: 1.9498 - val_accuracy: 0.3210\n",
      "Epoch 61/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8818 - accuracy: 0.3365 - val_loss: 1.9503 - val_accuracy: 0.3224\n",
      "Epoch 62/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8810 - accuracy: 0.3369 - val_loss: 1.9553 - val_accuracy: 0.3266\n",
      "Epoch 63/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8804 - accuracy: 0.3386 - val_loss: 1.9561 - val_accuracy: 0.3221\n",
      "Epoch 64/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8802 - accuracy: 0.3374 - val_loss: 1.9551 - val_accuracy: 0.3199\n",
      "Epoch 65/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8799 - accuracy: 0.3374 - val_loss: 1.9513 - val_accuracy: 0.3235\n",
      "Epoch 66/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8784 - accuracy: 0.3372 - val_loss: 1.9562 - val_accuracy: 0.3248\n",
      "Epoch 67/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8780 - accuracy: 0.3407 - val_loss: 1.9561 - val_accuracy: 0.3188\n",
      "Epoch 68/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8779 - accuracy: 0.3382 - val_loss: 1.9554 - val_accuracy: 0.3204\n",
      "Epoch 69/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8773 - accuracy: 0.3385 - val_loss: 1.9562 - val_accuracy: 0.3237\n",
      "Epoch 70/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8766 - accuracy: 0.3392 - val_loss: 1.9611 - val_accuracy: 0.3211\n",
      "Epoch 71/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8777 - accuracy: 0.3381 - val_loss: 1.9549 - val_accuracy: 0.3199\n",
      "Epoch 72/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8752 - accuracy: 0.3396 - val_loss: 1.9557 - val_accuracy: 0.3230\n",
      "Epoch 73/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8758 - accuracy: 0.3390 - val_loss: 1.9593 - val_accuracy: 0.3222\n",
      "Epoch 74/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8748 - accuracy: 0.3381 - val_loss: 1.9595 - val_accuracy: 0.3208\n",
      "Epoch 75/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8744 - accuracy: 0.3392 - val_loss: 1.9547 - val_accuracy: 0.3228\n",
      "Epoch 76/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8743 - accuracy: 0.3398 - val_loss: 1.9561 - val_accuracy: 0.3190\n",
      "Epoch 77/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8738 - accuracy: 0.3380 - val_loss: 1.9592 - val_accuracy: 0.3211\n",
      "Epoch 78/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8741 - accuracy: 0.3392 - val_loss: 1.9561 - val_accuracy: 0.3201\n",
      "Epoch 79/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8726 - accuracy: 0.3408 - val_loss: 1.9564 - val_accuracy: 0.3250\n",
      "Epoch 80/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8721 - accuracy: 0.3396 - val_loss: 1.9579 - val_accuracy: 0.3217\n",
      "Epoch 81/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8724 - accuracy: 0.3388 - val_loss: 1.9615 - val_accuracy: 0.3175\n",
      "Epoch 82/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8713 - accuracy: 0.3422 - val_loss: 1.9566 - val_accuracy: 0.3224\n",
      "Epoch 83/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8714 - accuracy: 0.3393 - val_loss: 1.9588 - val_accuracy: 0.3195\n",
      "Epoch 84/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8714 - accuracy: 0.3409 - val_loss: 1.9591 - val_accuracy: 0.3171\n",
      "Epoch 85/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8705 - accuracy: 0.3399 - val_loss: 1.9608 - val_accuracy: 0.3153\n",
      "Epoch 86/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8708 - accuracy: 0.3398 - val_loss: 1.9579 - val_accuracy: 0.3221\n",
      "Epoch 87/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8697 - accuracy: 0.3412 - val_loss: 1.9699 - val_accuracy: 0.3159\n",
      "Epoch 88/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8692 - accuracy: 0.3415 - val_loss: 1.9624 - val_accuracy: 0.3199\n",
      "Epoch 89/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8689 - accuracy: 0.3418 - val_loss: 1.9574 - val_accuracy: 0.3191\n",
      "Epoch 90/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8689 - accuracy: 0.3414 - val_loss: 1.9593 - val_accuracy: 0.3219\n",
      "Epoch 91/200\n",
      "974/974 [==============================] - 2s 2ms/step - loss: 1.8683 - accuracy: 0.3413 - val_loss: 1.9630 - val_accuracy: 0.3206\n",
      "Epoch 92/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8683 - accuracy: 0.3398 - val_loss: 1.9608 - val_accuracy: 0.3215\n",
      "Epoch 93/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8678 - accuracy: 0.3421 - val_loss: 1.9605 - val_accuracy: 0.3144\n",
      "Epoch 94/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8679 - accuracy: 0.3408 - val_loss: 1.9604 - val_accuracy: 0.3241\n",
      "Epoch 95/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8672 - accuracy: 0.3420 - val_loss: 1.9637 - val_accuracy: 0.3195\n",
      "Epoch 96/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8666 - accuracy: 0.3438 - val_loss: 1.9626 - val_accuracy: 0.3210\n",
      "Epoch 97/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8671 - accuracy: 0.3419 - val_loss: 1.9626 - val_accuracy: 0.3179\n",
      "Epoch 98/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8663 - accuracy: 0.3426 - val_loss: 1.9623 - val_accuracy: 0.3173\n",
      "Epoch 99/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8652 - accuracy: 0.3431 - val_loss: 1.9641 - val_accuracy: 0.3175\n",
      "Epoch 100/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8661 - accuracy: 0.3418 - val_loss: 1.9599 - val_accuracy: 0.3168\n",
      "Epoch 101/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8649 - accuracy: 0.3439 - val_loss: 1.9618 - val_accuracy: 0.3168\n",
      "Epoch 102/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8650 - accuracy: 0.3429 - val_loss: 1.9648 - val_accuracy: 0.3141\n",
      "Epoch 103/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8648 - accuracy: 0.3435 - val_loss: 1.9633 - val_accuracy: 0.3175\n",
      "Epoch 104/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8644 - accuracy: 0.3432 - val_loss: 1.9623 - val_accuracy: 0.3177\n",
      "Epoch 105/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.8639 - accuracy: 0.3435 - val_loss: 1.9636 - val_accuracy: 0.3226\n",
      "Epoch 106/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8634 - accuracy: 0.3429 - val_loss: 1.9660 - val_accuracy: 0.3193\n",
      "Epoch 107/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8636 - accuracy: 0.3432 - val_loss: 1.9651 - val_accuracy: 0.3230\n",
      "Epoch 108/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.8631 - accuracy: 0.3429 - val_loss: 1.9654 - val_accuracy: 0.3186\n",
      "Epoch 109/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8628 - accuracy: 0.3429 - val_loss: 1.9652 - val_accuracy: 0.3248\n",
      "Epoch 110/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8628 - accuracy: 0.3449 - val_loss: 1.9690 - val_accuracy: 0.3148\n",
      "Epoch 111/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8626 - accuracy: 0.3455 - val_loss: 1.9663 - val_accuracy: 0.3208\n",
      "Epoch 112/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8619 - accuracy: 0.3433 - val_loss: 1.9670 - val_accuracy: 0.3215\n",
      "Epoch 113/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8615 - accuracy: 0.3443 - val_loss: 1.9660 - val_accuracy: 0.3230\n",
      "Epoch 114/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8614 - accuracy: 0.3440 - val_loss: 1.9675 - val_accuracy: 0.3182\n",
      "Epoch 115/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8613 - accuracy: 0.3445 - val_loss: 1.9663 - val_accuracy: 0.3215\n",
      "Epoch 116/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8613 - accuracy: 0.3445 - val_loss: 1.9673 - val_accuracy: 0.3188\n",
      "Epoch 117/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.8605 - accuracy: 0.3455 - val_loss: 1.9662 - val_accuracy: 0.3202\n",
      "Epoch 118/200\n",
      "974/974 [==============================] - 2s 2ms/step - loss: 1.8609 - accuracy: 0.3438 - val_loss: 1.9679 - val_accuracy: 0.3173\n",
      "Epoch 119/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8602 - accuracy: 0.3437 - val_loss: 1.9681 - val_accuracy: 0.3186\n",
      "Epoch 120/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8598 - accuracy: 0.3440 - val_loss: 1.9701 - val_accuracy: 0.3211\n",
      "Epoch 121/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.8599 - accuracy: 0.3440 - val_loss: 1.9669 - val_accuracy: 0.3162\n",
      "Epoch 122/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8597 - accuracy: 0.3441 - val_loss: 1.9640 - val_accuracy: 0.3228\n",
      "Epoch 123/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8591 - accuracy: 0.3441 - val_loss: 1.9675 - val_accuracy: 0.3162\n",
      "Epoch 124/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8592 - accuracy: 0.3444 - val_loss: 1.9705 - val_accuracy: 0.3170\n",
      "Epoch 125/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8585 - accuracy: 0.3456 - val_loss: 1.9713 - val_accuracy: 0.3164\n",
      "Epoch 126/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8584 - accuracy: 0.3433 - val_loss: 1.9702 - val_accuracy: 0.3182\n",
      "Epoch 127/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8586 - accuracy: 0.3444 - val_loss: 1.9689 - val_accuracy: 0.3182\n",
      "Epoch 128/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8581 - accuracy: 0.3441 - val_loss: 1.9695 - val_accuracy: 0.3179\n",
      "Epoch 129/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8578 - accuracy: 0.3449 - val_loss: 1.9679 - val_accuracy: 0.3164\n",
      "Epoch 130/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8578 - accuracy: 0.3465 - val_loss: 1.9686 - val_accuracy: 0.3186\n",
      "Epoch 131/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8570 - accuracy: 0.3453 - val_loss: 1.9708 - val_accuracy: 0.3197\n",
      "Epoch 132/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8574 - accuracy: 0.3460 - val_loss: 1.9694 - val_accuracy: 0.3193\n",
      "Epoch 133/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8570 - accuracy: 0.3444 - val_loss: 1.9716 - val_accuracy: 0.3202\n",
      "Epoch 134/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8566 - accuracy: 0.3464 - val_loss: 1.9696 - val_accuracy: 0.3168\n",
      "Epoch 135/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8563 - accuracy: 0.3455 - val_loss: 1.9732 - val_accuracy: 0.3157\n",
      "Epoch 136/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8565 - accuracy: 0.3459 - val_loss: 1.9718 - val_accuracy: 0.3148\n",
      "Epoch 137/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8562 - accuracy: 0.3450 - val_loss: 1.9723 - val_accuracy: 0.3184\n",
      "Epoch 138/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.8558 - accuracy: 0.3453 - val_loss: 1.9723 - val_accuracy: 0.3179\n",
      "Epoch 139/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.8562 - accuracy: 0.3453 - val_loss: 1.9731 - val_accuracy: 0.3162\n",
      "Epoch 140/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8556 - accuracy: 0.3449 - val_loss: 1.9713 - val_accuracy: 0.3164\n",
      "Epoch 141/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.8552 - accuracy: 0.3448 - val_loss: 1.9718 - val_accuracy: 0.3159\n",
      "Epoch 142/200\n",
      "974/974 [==============================] - 2s 2ms/step - loss: 1.8555 - accuracy: 0.3450 - val_loss: 1.9722 - val_accuracy: 0.3201\n",
      "Epoch 143/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8549 - accuracy: 0.3459 - val_loss: 1.9752 - val_accuracy: 0.3166\n",
      "Epoch 144/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8546 - accuracy: 0.3463 - val_loss: 1.9754 - val_accuracy: 0.3177\n",
      "Epoch 145/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8544 - accuracy: 0.3456 - val_loss: 1.9740 - val_accuracy: 0.3162\n",
      "Epoch 146/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8544 - accuracy: 0.3462 - val_loss: 1.9736 - val_accuracy: 0.3177\n",
      "Epoch 147/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8543 - accuracy: 0.3467 - val_loss: 1.9757 - val_accuracy: 0.3162\n",
      "Epoch 148/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8542 - accuracy: 0.3462 - val_loss: 1.9745 - val_accuracy: 0.3190\n",
      "Epoch 149/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8540 - accuracy: 0.3475 - val_loss: 1.9760 - val_accuracy: 0.3195\n",
      "Epoch 150/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8536 - accuracy: 0.3454 - val_loss: 1.9762 - val_accuracy: 0.3148\n",
      "Epoch 151/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8539 - accuracy: 0.3482 - val_loss: 1.9738 - val_accuracy: 0.3177\n",
      "Epoch 152/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8531 - accuracy: 0.3470 - val_loss: 1.9746 - val_accuracy: 0.3168\n",
      "Epoch 153/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8527 - accuracy: 0.3454 - val_loss: 1.9740 - val_accuracy: 0.3211\n",
      "Epoch 154/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8530 - accuracy: 0.3456 - val_loss: 1.9772 - val_accuracy: 0.3175\n",
      "Epoch 155/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8529 - accuracy: 0.3471 - val_loss: 1.9762 - val_accuracy: 0.3177\n",
      "Epoch 156/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8525 - accuracy: 0.3469 - val_loss: 1.9784 - val_accuracy: 0.3164\n",
      "Epoch 157/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8526 - accuracy: 0.3469 - val_loss: 1.9768 - val_accuracy: 0.3184\n",
      "Epoch 158/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8524 - accuracy: 0.3480 - val_loss: 1.9751 - val_accuracy: 0.3150\n",
      "Epoch 159/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8519 - accuracy: 0.3468 - val_loss: 1.9791 - val_accuracy: 0.3168\n",
      "Epoch 160/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8519 - accuracy: 0.3465 - val_loss: 1.9775 - val_accuracy: 0.3190\n",
      "Epoch 161/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8519 - accuracy: 0.3478 - val_loss: 1.9787 - val_accuracy: 0.3181\n",
      "Epoch 162/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8515 - accuracy: 0.3482 - val_loss: 1.9782 - val_accuracy: 0.3195\n",
      "Epoch 163/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8514 - accuracy: 0.3475 - val_loss: 1.9768 - val_accuracy: 0.3181\n",
      "Epoch 164/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8510 - accuracy: 0.3468 - val_loss: 1.9796 - val_accuracy: 0.3166\n",
      "Epoch 165/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8514 - accuracy: 0.3483 - val_loss: 1.9769 - val_accuracy: 0.3168\n",
      "Epoch 166/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8508 - accuracy: 0.3473 - val_loss: 1.9771 - val_accuracy: 0.3171\n",
      "Epoch 167/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8508 - accuracy: 0.3475 - val_loss: 1.9780 - val_accuracy: 0.3164\n",
      "Epoch 168/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8508 - accuracy: 0.3474 - val_loss: 1.9801 - val_accuracy: 0.3168\n",
      "Epoch 169/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8503 - accuracy: 0.3483 - val_loss: 1.9804 - val_accuracy: 0.3190\n",
      "Epoch 170/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8501 - accuracy: 0.3479 - val_loss: 1.9784 - val_accuracy: 0.3181\n",
      "Epoch 171/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8504 - accuracy: 0.3470 - val_loss: 1.9796 - val_accuracy: 0.3177\n",
      "Epoch 172/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8500 - accuracy: 0.3485 - val_loss: 1.9804 - val_accuracy: 0.3166\n",
      "Epoch 173/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8497 - accuracy: 0.3480 - val_loss: 1.9809 - val_accuracy: 0.3188\n",
      "Epoch 174/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8497 - accuracy: 0.3477 - val_loss: 1.9797 - val_accuracy: 0.3201\n",
      "Epoch 175/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8497 - accuracy: 0.3483 - val_loss: 1.9796 - val_accuracy: 0.3186\n",
      "Epoch 176/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8491 - accuracy: 0.3472 - val_loss: 1.9847 - val_accuracy: 0.3171\n",
      "Epoch 177/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8495 - accuracy: 0.3471 - val_loss: 1.9822 - val_accuracy: 0.3215\n",
      "Epoch 178/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8487 - accuracy: 0.3480 - val_loss: 1.9802 - val_accuracy: 0.3186\n",
      "Epoch 179/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8487 - accuracy: 0.3482 - val_loss: 1.9832 - val_accuracy: 0.3184\n",
      "Epoch 180/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8487 - accuracy: 0.3473 - val_loss: 1.9826 - val_accuracy: 0.3150\n",
      "Epoch 181/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8484 - accuracy: 0.3477 - val_loss: 1.9820 - val_accuracy: 0.3159\n",
      "Epoch 182/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8484 - accuracy: 0.3477 - val_loss: 1.9822 - val_accuracy: 0.3164\n",
      "Epoch 183/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8481 - accuracy: 0.3484 - val_loss: 1.9853 - val_accuracy: 0.3173\n",
      "Epoch 184/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8484 - accuracy: 0.3488 - val_loss: 1.9827 - val_accuracy: 0.3202\n",
      "Epoch 185/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8479 - accuracy: 0.3471 - val_loss: 1.9851 - val_accuracy: 0.3181\n",
      "Epoch 186/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8482 - accuracy: 0.3477 - val_loss: 1.9838 - val_accuracy: 0.3171\n",
      "Epoch 187/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8479 - accuracy: 0.3494 - val_loss: 1.9809 - val_accuracy: 0.3170\n",
      "Epoch 188/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8477 - accuracy: 0.3482 - val_loss: 1.9827 - val_accuracy: 0.3171\n",
      "Epoch 189/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8474 - accuracy: 0.3489 - val_loss: 1.9850 - val_accuracy: 0.3184\n",
      "Epoch 190/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8475 - accuracy: 0.3492 - val_loss: 1.9842 - val_accuracy: 0.3166\n",
      "Epoch 191/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8473 - accuracy: 0.3485 - val_loss: 1.9837 - val_accuracy: 0.3197\n",
      "Epoch 192/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8470 - accuracy: 0.3487 - val_loss: 1.9831 - val_accuracy: 0.3201\n",
      "Epoch 193/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.8469 - accuracy: 0.3506 - val_loss: 1.9842 - val_accuracy: 0.3177\n",
      "Epoch 194/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8466 - accuracy: 0.3493 - val_loss: 1.9866 - val_accuracy: 0.3186\n",
      "Epoch 195/200\n",
      "974/974 [==============================] - 1s 2ms/step - loss: 1.8467 - accuracy: 0.3487 - val_loss: 1.9850 - val_accuracy: 0.3171\n",
      "Epoch 196/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8466 - accuracy: 0.3490 - val_loss: 1.9860 - val_accuracy: 0.3193\n",
      "Epoch 197/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8466 - accuracy: 0.3490 - val_loss: 1.9862 - val_accuracy: 0.3179\n",
      "Epoch 198/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8465 - accuracy: 0.3475 - val_loss: 1.9871 - val_accuracy: 0.3191\n",
      "Epoch 199/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8461 - accuracy: 0.3489 - val_loss: 1.9852 - val_accuracy: 0.3199\n",
      "Epoch 200/200\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.8460 - accuracy: 0.3486 - val_loss: 1.9847 - val_accuracy: 0.3181\n",
      "128/128 [==============================] - 0s 869us/step - loss: 1.9703 - accuracy: 0.3270\n",
      "The loss function on our test set: 1.9703469276428223\n",
      "Accuracy on our test set: 0.327031672000885\n"
     ]
    }
   ],
   "source": [
    "network = Sequential()\n",
    "network.add(Dense(units=128, activation='relu'))\n",
    "network.add(Dense(units=128, activation='relu'))\n",
    "network.add(Dense(units=64, activation='relu'))\n",
    "network.add(Dense(units=14, activation='softmax'))\n",
    "opt=keras.optimizers.Adam(learning_rate=0.01,decay=0.0005)\n",
    "network.compile(\n",
    "  optimizer = opt,\n",
    "  loss = 'categorical_crossentropy', \n",
    "  metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "network.fit(X_train,y_train_cat,validation_data=(X_val,y_val_cat),epochs=200)\n",
    "test_loss, test_acc = network.evaluate(X_test,y_test_cat)\n",
    "\n",
    "print('The loss function on our test set: ' + str(test_loss))\n",
    "print('Accuracy on our test set: ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3602065ee927684796035b87177ef431ab9ade38c6fe389b7b9dcf8c0b728ff8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}