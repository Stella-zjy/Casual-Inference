{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we preprocess the data. Replace the string in original data with integer to make it easy for us to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  workclass  ...  native_country  income_bigger_than_50K\n",
      "0       67          0  ...               0                       1\n",
      "1       17          0  ...               0                       0\n",
      "2       31          0  ...               0                       1\n",
      "3       58          1  ...               0                       0\n",
      "4       25          1  ...               0                       0\n",
      "...    ...        ...  ...             ...                     ...\n",
      "43952   52          0  ...               0                       1\n",
      "43953   19          0  ...               0                       0\n",
      "43954   30          0  ...               0                       0\n",
      "43955   46          0  ...               0                       0\n",
      "43956   30          0  ...               0                       0\n",
      "\n",
      "[40727 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "from tkinter.messagebox import RETRY\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import graphviz as gr\n",
    "from linearmodels.iv import IV2SLS\n",
    "pd.set_option(\"display.max_columns\", 5)\n",
    "style.use(\"fivethirtyeight\")\n",
    "relative_path = \"..\"\n",
    "\n",
    "def get_dataset():\n",
    "    data = pd.read_csv(relative_path + \"/data/income_data/train.csv\")\n",
    "    data = data.dropna(axis=0)\n",
    "    data.rename(columns={'educational-num': 'educational_num', \"income_>50K\": \"income_bigger_than_50K\",\n",
    "                         'marital-status': 'marital_status', 'native-country': 'native_country'}, inplace=True)\n",
    "    data[\"race\"] = data[\"race\"].replace(to_replace=\"Amer-Indian-Eskimo\",\n",
    "                                        value=\"Indian\")\n",
    "    data[\"race\"] = data[\"race\"].replace(to_replace=\"Asian-Pac-Islander\",\n",
    "                                        value=\"Asian\")\n",
    "\n",
    "    occupationDict = {\n",
    "        \"Exec-managerial\": 0,\n",
    "        \"Other-service\": 4,\n",
    "        \"Transport-moving\": 5,\n",
    "        \"Adm-clerical\": 6,\n",
    "        \"Machine-op-inspct\": 5,\n",
    "        \"Sales\": 3,\n",
    "        \"Handlers-cleaners\": 5,\n",
    "        \"Farming-fishing\": 5,\n",
    "        \"Protective-serv\": 2,\n",
    "        \"Prof-specialty\": 2,\n",
    "        \"Craft-repair\": 1,\n",
    "        \"Tech-support\": 5,\n",
    "        \"Priv-house-serv\": 5,\n",
    "        \"Armed-Forces\": 5\n",
    "    }\n",
    "    data[\"occupation\"] = data[\"occupation\"].map(occupationDict)\n",
    "    raceDict = {\n",
    "        \"White\": 0,\n",
    "        \"Black\": 1,\n",
    "        \"Asian\": 2,\n",
    "        \"Indian\": 2,\n",
    "        \"Other\": 2\n",
    "    }\n",
    "    data[\"race\"] = data[\"race\"].map(raceDict)\n",
    "    genderDict = {\n",
    "        \"Male\": 0,\n",
    "        \"Female\": 1\n",
    "    }\n",
    "    data[\"gender\"] = data[\"gender\"].map(genderDict)\n",
    "    maritalDict = {\n",
    "        \"Divorced\": 2,\n",
    "        \"Never-married\": 1,\n",
    "        \"Married-civ-spouse\": 0,\n",
    "        \"Widowed\": 2,\n",
    "        \"Separated\": 2,\n",
    "        \"Married-spouse-absent\": 2,\n",
    "        \"Married-AF-spouse\": 2\n",
    "    }\n",
    "    data[\"marital_status\"] = data[\"marital_status\"].map(maritalDict)\n",
    "    def map_country(native_country):\n",
    "        if native_country == \"United-States\":\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    data[\"native_country\"] = data[\"native_country\"].map(map_country)\n",
    "    workclassDict = {\n",
    "        'Private': 0,\n",
    "        'State-gov': 1,\n",
    "        'Self-emp-not-inc': 2,\n",
    "        'Federal-gov': 1,\n",
    "        'Local-gov': 1,\n",
    "        'Self-emp-inc': 1,\n",
    "        'Without-pay': 1\n",
    "    }\n",
    "    data[\"workclass\"] = data[\"workclass\"].map(workclassDict)\n",
    "    educationDict = {\n",
    "        'Doctorate': 1,\n",
    "        '12th': 0,\n",
    "        'Bachelors': 1,\n",
    "        '7th-8th': 0,\n",
    "        'Some-college': 1,\n",
    "        'HS-grad': 0,\n",
    "        '9th': 0,\n",
    "        '10th': 0,\n",
    "        '11th': 0,\n",
    "        'Masters': 1,\n",
    "        'Preschool': 0,\n",
    "        '5th-6th': 0,\n",
    "        'Prof-school': 0,\n",
    "        'Assoc-voc': 0,\n",
    "        'Assoc-acdm': 0,\n",
    "        '1st-4th': 0\n",
    "    }\n",
    "    data[\"education\"] = data[\"education\"].map(educationDict)\n",
    "    def map_relationship(relationship):\n",
    "        if relationship == \"Husband\":\n",
    "            return 0\n",
    "        if relationship == \"Not-in-family\":\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    data[\"relationship\"] = data[\"relationship\"].map(map_relationship)\n",
    "    data.to_csv(relative_path + \"/data/income_data/modified_train.csv\")\n",
    "    return data\n",
    "print(get_dataset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Modify the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class imcomedataset(Dataset):\n",
    "\n",
    "  def __init__(self,train_data,train_outcome,prob):\n",
    "\n",
    "    self.x_train = torch.tensor(train_data, dtype=torch.float32)\n",
    "    self.y_train = torch.tensor(train_outcome, dtype=torch.float32)\n",
    "    self.prob = torch.from_numpy(prob.to_numpy())\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.y_train)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    return self.x_train[idx],self.y_train[idx],self.prob[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then we modify the training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_fc = nn.Linear(input_dim, 10)\n",
    "        self.hidden_fc = nn.Linear(10, 10)\n",
    "        self.output_fc = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x = [batch size, height, width]\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        # x = [batch size, height * width]\n",
    "\n",
    "        h_1 = F.relu(self.input_fc(x))\n",
    "        # h_1 = [batch size, 250]\n",
    "\n",
    "        h_2 = F.relu(self.hidden_fc(h_1))\n",
    "        # h_2 = [batch size, 100]\n",
    "\n",
    "        h3 = self.output_fc(h_2)\n",
    "        # y_pred = [batch size, output dim]\n",
    "\n",
    "\n",
    "        y_pred = F.sigmoid(h3)\n",
    "        #y_pred = F.softmax(h3, dim=1)\n",
    "        return y_pred, h3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Modify the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "\n",
    "class CustomLoss(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, predict_y, y,p):\n",
    "\n",
    "        temp = y - torch.mul(predict_y, p)\n",
    "\n",
    "        return torch.mean(torch.square(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88     22252\n",
      "           1       0.86      0.83      0.85     18475\n",
      "\n",
      "    accuracy                           0.86     40727\n",
      "   macro avg       0.86      0.86      0.86     40727\n",
      "weighted avg       0.86      0.86      0.86     40727\n",
      "\n",
      "Successful saved!\n",
      "       workclass  age  ...  p998  p999\n",
      "0              0   67  ...     1     1\n",
      "1              0   17  ...     0     0\n",
      "2              0   31  ...     0     0\n",
      "3              1   58  ...     0     0\n",
      "4              1   25  ...     1     0\n",
      "...          ...  ...  ...   ...   ...\n",
      "40722          0   52  ...     1     1\n",
      "40723          0   19  ...     1     0\n",
      "40724          0   30  ...     1     1\n",
      "40725          0   46  ...     0     0\n",
      "40726          0   30  ...     0     0\n",
      "\n",
      "[40727 rows x 1009 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from data_processor import get_xp\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# this function will sample based on the probility and times give.\n",
    "# the return is a list of samples\n",
    "def repeat_sample(times=1, possiblity=0.5):\n",
    "    temp = []\n",
    "\n",
    "    def sample(num):\n",
    "        u = np.random.rand()\n",
    "\n",
    "        return 1 if u < num else 0\n",
    "\n",
    "    for i in range(times):\n",
    "        a = sample(possiblity)\n",
    "        temp.append(a)\n",
    "\n",
    "    return temp\n",
    "\n",
    "\n",
    "# this function will build the new treatments\n",
    "def build(x, probilities, times=1, save=False):\n",
    "    treatments = [repeat_sample(times, i) for i in probilities]\n",
    "    data = np.hstack((x.to_numpy(), treatments))\n",
    "    new = pd.DataFrame(data, columns=list(x.columns)\n",
    "                                     + [\"p\" + str(i) for i in range(0, times)])\n",
    "\n",
    "    if save:\n",
    "        new.to_csv(\"../data/income_data/new X.csv\")\n",
    "        print(\"Successful saved!\")\n",
    "\n",
    "    return new\n",
    "\n",
    "\n",
    "# this function will do the first stage and return a new x.\n",
    "# ml method will have 4 opinions\n",
    "# save will auto save the new x with sample result to a csv file.\n",
    "def solve_stage_one(ml_method=\"LR\", save=False):\n",
    "    x, y = get_xp()\n",
    "\n",
    "    d = {\n",
    "        \"LR\": LogisticRegression(),\n",
    "        \"ADA\": AdaBoostClassifier(),\n",
    "        \"FOREST\": RandomForestClassifier(),\n",
    "        \"MLP\": MLPClassifier(),\n",
    "    }\n",
    "\n",
    "    model = d[ml_method.upper()]\n",
    "    clf = model.fit(x, y)\n",
    "    pred = clf.predict(x)\n",
    "    probilities = clf.predict_proba(x)[:, 1]\n",
    "    print(classification_report(y, pred))\n",
    "\n",
    "    new_x = build(x, probilities, 1000, save)\n",
    "\n",
    "    return new_x\n",
    "\n",
    "print(solve_stage_one(\"FOREST\", save=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Second Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 4s\n",
      "Train Loss: 0.179 | Train Acc: 75.44%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.172 | Train Acc: 76.88%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.171 | Train Acc: 76.73%\n",
      "Epoch: 04 | Epoch Time: 0m 4s\n",
      "Train Loss: 0.171 | Train Acc: 75.57%\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.171 | Train Acc: 74.98%\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.170 | Train Acc: 73.40%\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.168 | Train Acc: 76.58%\n",
      "Epoch: 08 | Epoch Time: 0m 4s\n",
      "Train Loss: 0.167 | Train Acc: 74.09%\n",
      "Epoch: 09 | Epoch Time: 0m 4s\n",
      "Train Loss: 0.168 | Train Acc: 74.50%\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.167 | Train Acc: 76.87%\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.167 | Train Acc: 75.01%\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.167 | Train Acc: 77.53%\n",
      "Epoch: 13 | Epoch Time: 0m 4s\n",
      "Train Loss: 0.167 | Train Acc: 72.53%\n",
      "Epoch: 14 | Epoch Time: 0m 4s\n",
      "Train Loss: 0.167 | Train Acc: 74.32%\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.167 | Train Acc: 75.03%\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.167 | Train Acc: 77.97%\n",
      "Epoch: 17 | Epoch Time: 0m 4s\n",
      "Train Loss: 0.167 | Train Acc: 75.97%\n",
      "Epoch: 18 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.167 | Train Acc: 76.51%\n",
      "Epoch: 19 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 75.47%\n",
      "Epoch: 20 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 75.15%\n",
      "Epoch: 21 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 76.76%\n",
      "Epoch: 22 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 76.56%\n",
      "Epoch: 23 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 77.18%\n",
      "Epoch: 24 | Epoch Time: 0m 4s\n",
      "Train Loss: 0.166 | Train Acc: 75.52%\n",
      "Epoch: 25 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 75.51%\n",
      "Epoch: 26 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 73.98%\n",
      "Epoch: 27 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 76.24%\n",
      "Epoch: 28 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 77.15%\n",
      "Epoch: 29 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 76.99%\n",
      "Epoch: 30 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.165 | Train Acc: 77.03%\n",
      "Epoch: 31 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 77.01%\n",
      "Epoch: 32 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 74.38%\n",
      "Epoch: 33 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 77.48%\n",
      "Epoch: 34 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 76.59%\n",
      "Epoch: 35 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 77.11%\n",
      "Epoch: 36 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 78.01%\n",
      "Epoch: 37 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 75.27%\n",
      "Epoch: 38 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 76.54%\n",
      "Epoch: 39 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 76.68%\n",
      "Epoch: 40 | Epoch Time: 0m 4s\n",
      "Train Loss: 0.166 | Train Acc: 75.69%\n",
      "Epoch: 41 | Epoch Time: 0m 4s\n",
      "Train Loss: 0.165 | Train Acc: 77.68%\n",
      "Epoch: 42 | Epoch Time: 0m 5s\n",
      "Train Loss: 0.166 | Train Acc: 76.64%\n",
      "Epoch: 43 | Epoch Time: 0m 4s\n",
      "Train Loss: 0.165 | Train Acc: 76.02%\n",
      "Epoch: 44 | Epoch Time: 0m 4s\n",
      "Train Loss: 0.165 | Train Acc: 77.79%\n",
      "Epoch: 45 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.165 | Train Acc: 76.13%\n",
      "Epoch: 46 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.165 | Train Acc: 76.77%\n",
      "Epoch: 47 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.166 | Train Acc: 76.25%\n",
      "Epoch: 48 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.165 | Train Acc: 76.60%\n",
      "Epoch: 49 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.165 | Train Acc: 74.94%\n",
      "Epoch: 50 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.165 | Train Acc: 76.64%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.78      0.83     61270\n",
      "         1.0       0.52      0.71      0.60     20184\n",
      "\n",
      "    accuracy                           0.77     81454\n",
      "   macro avg       0.71      0.75      0.72     81454\n",
      "weighted avg       0.80      0.77      0.78     81454\n",
      "\n",
      "roc_auc_score:0.7480828580422282\n",
      "train_accuracy_score:0.7663834802465195\n",
      "---------------------------------------------------------------------------------------------------\n",
      "ATE = 0.14368846219952366\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_processor import solve_sample\n",
    "\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.input_fc = nn.Linear(input_dim, 10)\n",
    "        self.hidden_fc = nn.Linear(10, 10)\n",
    "        self.output_fc = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = [batch size, height, width]\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        # x = [batch size, height * width]\n",
    "        h_1 = F.relu(self.input_fc(x))\n",
    "        # h_1 = [batch size, 250]\n",
    "        h_2 = F.relu(self.hidden_fc(h_1))\n",
    "        # h_2 = [batch size, 100]\n",
    "        h3 = self.output_fc(h_2)\n",
    "        # y_pred = [batch size, output dim]\n",
    "        y_pred = F.sigmoid(h3)\n",
    "        #y_pred = F.softmax(h3, dim=1)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def epoch_time(self, start_time, end_time):\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_mins = int(elapsed_time / 60)\n",
    "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "        return elapsed_mins, elapsed_secs\n",
    "\n",
    "    def calculate_accuracy(self, y_pred, y):\n",
    "        # y_pred = y_pred.detach().numpy().flatten()\n",
    "        # y_fact = pd.read_csv('../data/income_data/modified_train.csv')[['education', 'income_bigger_than_50K']]\n",
    "        # correct = 0\n",
    "        # for i in range(len(y_pred)):\n",
    "        #     if y_pred[i] >= 0.5:\n",
    "        #         y_pred[i] = 1.0\n",
    "        #     else:\n",
    "        #         y_pred[i] = 0.0\n",
    "        # for i in range(len(y_fact)):\n",
    "        #     if y_fact[\"education\"][i] == 1:\n",
    "        #         correct += (float(y_fact[\"income_bigger_than_50K\"][i]) == y_pred[2 * i])\n",
    "        #     else:\n",
    "        #         correct += (float(y_fact[\"income_bigger_than_50K\"][i]) == y_pred[2 * i + 1])\n",
    "        # acc = float(correct) / float(len(y_fact))\n",
    "        top_pred = (y_pred>0.5).float()\n",
    "        correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "        acc = correct.float() / y.shape[0]\n",
    "        return acc\n",
    "\n",
    "    def evaluate_prediction(self, y_pred, y):\n",
    "        y_pred = y_pred.detach().numpy().flatten()\n",
    "        y = y.detach().numpy().flatten()\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] >= 0.5:\n",
    "                y_pred[i] = 1.0\n",
    "            else:\n",
    "                y_pred[i] = 0.0\n",
    "        return classification_report(y, y_pred), roc_auc_score(y, y_pred), accuracy_score(y, y_pred)\n",
    "\n",
    "\n",
    "    def plot_train_loss(self, EPOCHS, history_train_loss, lr):\n",
    "        plt.figure()\n",
    "        plt.plot([i+1 for i in range(EPOCHS)], history_train_loss)\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('train loss')\n",
    "        plt.title('training loss with learning rate '+str(lr))\n",
    "        # plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "  \n",
    "    def fit(self, x, y, prob, EPOCHS=50, lr=0.01, batch_size = 256):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        num_sample = len(x)\n",
    "        total_batch = num_sample // batch_size\n",
    "        \n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        prob = torch.tensor(prob, dtype=torch.float32)\n",
    "\n",
    "        history = []\n",
    "        for epoch in range(EPOCHS):\n",
    "            start_time = time.monotonic()\n",
    "\n",
    "            all_idx = np.arange(num_sample)\n",
    "            np.random.shuffle(all_idx)\n",
    "            \n",
    "            epoch_loss = 0\n",
    "\n",
    "            # Mini-batch Training\n",
    "            for batch_num in range(total_batch):\n",
    "                selected_idx = all_idx[batch_size*batch_num:(batch_num+1)*batch_size]\n",
    "                sub_x = x[selected_idx]\n",
    "                sub_y = y[selected_idx]\n",
    "                sub_prob = prob[selected_idx]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                pred_y = self.forward(sub_x)\n",
    "                \n",
    "                xent_loss = 0\n",
    "                for i in range(len(selected_idx)):\n",
    "                    xent_loss += (sub_y[i] - sub_prob[i] * pred_y[i])**2\n",
    "                          \n",
    "                loss = xent_loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += xent_loss\n",
    "\n",
    "            pred_y_eval = model.forward(x)\n",
    "\n",
    "            train_loss = epoch_loss.item() / num_sample\n",
    "            history.append(train_loss)\n",
    "            train_acc = self.calculate_accuracy(pred_y_eval, y)\n",
    "            end_time = time.monotonic()\n",
    "            epoch_mins, epoch_secs = self.epoch_time(start_time, end_time)\n",
    "\n",
    "            print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "            print(f'Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "\n",
    "            # Plot train loss & Print report after the last epoch\n",
    "            if epoch == EPOCHS-1:\n",
    "                self.plot_train_loss(EPOCHS, history, lr)\n",
    "                train_report, train_roc_auc_score, train_accuracy_score = self.evaluate_prediction(pred_y_eval, y)\n",
    "                print(train_report)\n",
    "                print(\"roc_auc_score:\" + str(train_roc_auc_score))\n",
    "                print(\"train_accuracy_score:\" + str(train_accuracy_score))\n",
    "                print(\"---------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        pred_y = self.forward(x)\n",
    "        pred_y = (pred_y>0.5).float().detach()\n",
    "        pred_y = torch.flatten(pred_y).numpy()\n",
    "        return pred_y\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# Stage 1 to Stage 2\n",
    "xp, probability = solve_sample()\n",
    "# Input value of the outcome network\n",
    "x = xp[[\"workclass\", \"marital_status\", \"occupation\", \"relationship\", \"gender\", \n",
    "        \"native_country\", \"age\", \"education\"]].to_numpy()\n",
    "# Groudtruth value of the outcome network\n",
    "y = xp[[\">=50K\"]].to_numpy()\n",
    "# Probability\n",
    "probability = probability.to_numpy()\n",
    "\n",
    "\n",
    "# Initialize input & output dimensions\n",
    "input_dim = x.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "\n",
    "###\n",
    "model = MLP(input_dim, output_dim)\n",
    "model.fit(x, y, probability)\n",
    "\n",
    "\n",
    "\n",
    "# Counterfactual Prediction & Calculate ATE\n",
    "\n",
    "def calculate_ate(y_pred, y_fact):\n",
    "    ate = 0\n",
    "    size = len(y_fact)\n",
    "    for i in range(size):\n",
    "        if y_fact['education'][i] == 1:\n",
    "            ite = y_fact['income_bigger_than_50K'][i] - y_pred[2*i+1]\n",
    "        else:\n",
    "            ite = y_pred[2*i] - y_fact['income_bigger_than_50K'][i]\n",
    "        ate += ite\n",
    "    ate = ate / size\n",
    "    return ate\n",
    "\n",
    "y_pred = model.predict(x)\n",
    "y_fact = pd.read_csv('../data/income_data/modified_train.csv')[['education','income_bigger_than_50K']]\n",
    "\n",
    "print('ATE = '+ str(calculate_ate(y_pred, y_fact)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
